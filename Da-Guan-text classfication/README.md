# 2018“达观杯”文本智能处理挑战赛

* Task:文本分类问题

比赛详情 [达观杯文本智能处理挑战赛](http://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E7%AB%9E%E8%B5%9B%E4%BF%A1%E6%81%AF.html) 

排名情况 [排行榜](https://www.dcjingsai.com/common/cmpt/%E2%80%9C%E8%BE%BE%E8%A7%82%E6%9D%AF%E2%80%9D%E6%96%87%E6%9C%AC%E6%99%BA%E8%83%BD%E5%A4%84%E7%90%86%E6%8C%91%E6%88%98%E8%B5%9B_%E6%8E%92%E8%A1%8C%E6%A6%9C.html)

## 比赛任务描述
- 1.  任务

这个文本分类的问题实际上是一个对于长文本的正文，预测其所属类别，共19个分类别。  

- 2.  数据介绍

训练数据和测试数据分别有十万条数据，每个数据集的每个样本都是一篇长文章，文章又分别有两种表示：一种是字表示，就是文章给出字顺序的表示，即article；一种是词表示，就是文章做了分词处理，给出词顺序的表示，即word。

还要注意的是所有的数据进行了脱敏处理，就是说数据中我们看不到具体的字或者词，只有他们的数字ID，每一个id表示一个字或者一个词。

- 3.	数据初步探索

共有1万多个不同的汉字，以及84万个不同的词。全部文章，平均有1177个字，719个词，显然这是一个关于长文本的分类问题，也是这次比赛比较关键的难点。
我将训练集集按照9:1划分为训练集和验证集，希望用将近9万条样本来训练我的深度网络，并且根据验证集上面的表现来调参以及设置模型终止条件。由于有需要用到RNN等序列模型的结构，为了计算效率，我对文章进行了阶段补齐，这里分别对文章的词表示word按照长度2000来截断或者补齐，而文章的字表示按照长度3000来截断或者补齐。


## 代码环境  
基于pytorch，版本为0.4.1，python版本为3.6。  
需要安装的相关模块为：  
```
sklearn
pandas
numpy
fire
pytorch
torchtext
word2vec
```

## 文件目录说明  
```
文件夹介绍
	——dataset:
		训练集和测试集放入该文件夹下。数据集到比赛官网上下载
	——emb_build:
		预训练词向量，词向量文件也在该文件夹下
	——ensemble:
		最后模型融合，文件夹下将需要融合的模型名字写到ensemble_list.txt文件中，然后执行ensemble.py即可
	    -result:
		模型融合后的预测数据在该文件夹下找到
	——models:
		所有用到的模型结构都在这个文件夹下，对应找到python文件查看具体结构
	——result：
		文件夹存储预测结果以及模型给出的概率预测（概率用于后面模型融合，很重要，存储为npy文件）
	——snapshot：
		这个文件夹下存储训练过程中的模型参数以及最终的模型权重
	——test_predict:
	——utils：
		主要是前期的数据集划分的文件
	——config.py:
		主要要设置的一些初始化参数
	——data.py:
		数据预处理
	——gen_test_result.py
	——local_concat_df.py
	——main.py:
		主要的训练函数在这
	——temp.py
```
具体的用法可以在对应的python文件（末尾）可以看到，或者文件夹下有对应的说明。


## 词向量预训练
这里我觉得需要先做词向量的预训练，但是由于比赛数据是经过脱敏处理的，所以不能使用现成的预训练好的优质的词向量，因此需要自己做一个词向量的预训练。网上已经有很多开源的预训练词向量的包，比赛中我采用的是word2vec模块对词向量进行预训练。
* 注意，尽管在后面训练神经网络的时候，不能用到测试集的数据进行训练，但是这里对于词向量的训练，我觉得可以充分用到测试集的语料（既然提供了就要充分利用），也就是我用了我所能利用的所有文章语料对我的网络词向量进行了训练，一开始我对词向量和字向量都训练出了300维的词向量表示，然后在后面的实验中就得到了非常不错的效果。（不过后续有想试不同纬度的预训练词向量，不过实验都跑不全，没有排查出原因。）

* 此外，我对我的所有模型都做了不预训练词向量的实验对比，发现，同个模型以及各种超参数不变的情况下，采用预训练的词向量要比直接随机初始化词向量的实验结果F1指标要高0.03。比如说用了GRU，在本地验证集上，采用预训练的300维度词向量，F1指标为0.77+，而进行随机初始化的词向量的模型，F1指标为0.73+，将近0.03的差距足以拉开几百名的差距了。因此我认为预训练词向量绝对是我的比赛模型中最重要的一步之一。

当然，前面说到我这段时间看到的关于ELMo动态词向量模型，我有想往我的模型中加入，因为原论文提出这样的实验结论就是，ELMo在就加入到NLP下游任务的模型中，可以对baseline提高3个百分点的效果，因此如果我再引入ELMo的词向量结构进来，有可能成绩可以更好。不过这是之后要考虑的事情了，因为还没有研究完原始的代码，对于如何将其加入到我的模型结构中还没有什么经验，因此在这就不多做深入探索，留作后面的探索吧。

代码见emb_build文件夹下load_all_row_to_txt.py和train_emb.py，注意修改代码中训练集和测试集的文件路径，依次运行即可得到词向量文件word_300.txt和article_300.txt。
```
python load_all_row_to_txt.py
python train_emb.py
```

## 相关模型  
最开始，我采用了一个最最最简单的文本分类模型作为我的baseline，我对word（文章的词分割表示）采用计数向量（CountVector）作为特征，然后用简单的LR进行分类学习器，得到了验证集以及测试集上0.73+的表现效果，当然这个排名就非常靠后了。做这一步的目的是希望得到一个基准线（当然因为比赛已经结束了，可以在排名榜看到具体的F1指标排名，这里是想模拟比赛的过程所做的），在之后的模型学习中，希望我的网络能够在初步学习（最开始的几个epoch中）可以达到这样的基线，对于没有能够很快达到这个基线的模型就要考虑增加模型复杂度或者研究其结构参数等方面，对模型进行调整，方便我在短时间内可以得到多个模型，提高效率。

我采用的模型主要有以下几种：

* FastText  
* GRU  
* RCNN  
* LSTM  
* TextCNN  
* BiGRU with attention  

都是一些比较常见的分类模型，他们的结构都非常类似，都是首先将文本输入到embedding层得到词语的embedding表示，然后通过CNN或者RNN各种变体结构来提取文本高维特征，最终通过分类器softmax输出19维的向量，也就是各个分类的概率。

训练示例：
```
python main.py main  --model='GRU' --device=0 --Id='word2'  
python main.py main --model='GRU' --Id='word_noPretrained' --pretrained_emd=False --kmax_pooling=4 --seed=777 --device=0  
```


## 模型融合
等概率权重融合，所以前面每次训练完成保存的是概率值，然后执行文件夹ensemble下面的ensemble.py文件，就可以实现各个模型融合了。具体可以参见该目录下的介绍文件以及代码。
```
python ensemble.py main --list_txt='ensemble_list.txt'
```

